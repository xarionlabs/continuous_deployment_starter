# Production-ready Airflow configuration with LocalExecutor
# Uses PostgreSQL backend and simplified service architecture
---
services:

  airflow-webserver:
    image: apache/airflow:3.0.2
    entrypoint: ["/opt/airflow/custom-entrypoint.sh"]
    command: webserver
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      GOOGLE_OAUTH_CLIENT_ID: ${GOOGLE_OAUTH_CLIENT_ID:-}
      GOOGLE_OAUTH_CLIENT_SECRET: ${GOOGLE_OAUTH_CLIENT_SECRET:-}
      GOOGLE_OAUTH_DOMAIN_WHITELIST: ${GOOGLE_OAUTH_DOMAIN_WHITELIST:-}
      VIRTUAL_HOST: ${AIRFLOW_WEB_VIRTUAL_HOST}
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}:/opt/airflow
      - ./configure-db-entrypoint.sh:/opt/airflow/custom-entrypoint.sh:ro
      - ./webserver_config.py:/opt/airflow/webserver_config.py:ro
    secrets:
      - PSQL_AIRFLOW_PASSWORD
      - GOOGLE_OAUTH_CLIENT_SECRET
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      - airflow-init

  airflow-scheduler:
    image: apache/airflow:3.0.2
    entrypoint: ["/opt/airflow/custom-entrypoint.sh"]
    command: scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      GOOGLE_OAUTH_CLIENT_ID: ${GOOGLE_OAUTH_CLIENT_ID:-}
      GOOGLE_OAUTH_CLIENT_SECRET: ${GOOGLE_OAUTH_CLIENT_SECRET:-}
      GOOGLE_OAUTH_DOMAIN_WHITELIST: ${GOOGLE_OAUTH_DOMAIN_WHITELIST:-}
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}:/opt/airflow
      - ./configure-db-entrypoint.sh:/opt/airflow/custom-entrypoint.sh:ro
      - ./webserver_config.py:/opt/airflow/webserver_config.py:ro
    secrets:
      - PSQL_AIRFLOW_PASSWORD
      - GOOGLE_OAUTH_CLIENT_SECRET
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      - airflow-init

  airflow-init:
    image: apache/airflow:3.0.2
    entrypoint: /bin/bash
    restart: "no"
    command:
      - -c
      - |
        mkdir -p /opt/airflow/{logs,dags,plugins}
        exec /opt/airflow/custom-entrypoint.sh airflow db migrate
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      GOOGLE_OAUTH_CLIENT_ID: ${GOOGLE_OAUTH_CLIENT_ID:-}
      GOOGLE_OAUTH_CLIENT_SECRET: ${GOOGLE_OAUTH_CLIENT_SECRET:-}
      GOOGLE_OAUTH_DOMAIN_WHITELIST: ${GOOGLE_OAUTH_DOMAIN_WHITELIST:-}
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}:/opt/airflow
      - ./configure-db-entrypoint.sh:/opt/airflow/custom-entrypoint.sh:ro
      - ./webserver_config.py:/opt/airflow/webserver_config.py:ro
    secrets:
      - PSQL_AIRFLOW_PASSWORD
      - GOOGLE_OAUTH_CLIENT_SECRET

secrets:
  PSQL_AIRFLOW_PASSWORD:
    external: true
  GOOGLE_OAUTH_CLIENT_SECRET:
    external: true

